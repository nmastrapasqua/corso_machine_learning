{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting e regolarizzazione\n",
    "L'overfitting è un problema tipico del machine learning che si manifesta quando un modello si lega troppo ai dati di addestramento e fallisce nel generalizzare su dati nuovi.\n",
    "\n",
    "L'overffiting è caratterizzato da:\n",
    "* **Alta variaza**: le previsioni per modelli addestrati con diverse parti del dataset saranno molto diverse tra loro.\n",
    "* **Basso bias**: l'errore per le predizioni sul set di addestramento è mediamente molto basso.\n",
    "<img src=\"res/overfitting.png\" width=\"500px\" /><br>\n",
    "In questo notebook utilizzremo scikit-learn e il Boston Housing Dataset per studiare da vicino il problema dell'overfitting ed imparare a constrastarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importiamo il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0    15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0    17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0    17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0    18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0    18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\", sep='\\s+', \n",
    "                     names=[\"CRIM\", \"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PRATIO\",\"B\",\"LSTAT\",\"MEDV\"])\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.drop('MEDV',axis=1).values\n",
    "Y = boston['MEDV'].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creiamo le features polinomiali\n",
    "Per correggere l'overfitting prima dobbiamo causarlo, un buon modo è aumentare la complessità del nostro modello aumentando il numero di features utilizzando i polinomi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di esempi nel test di addestramento: 354\n",
      "Numero di features: 105\n"
     ]
    }
   ],
   "source": [
    "polyfeats = PolynomialFeatures(degree=2)\n",
    "X_train_poly = polyfeats.fit_transform(X_train)\n",
    "X_test_poly = polyfeats.transform(X_test)\n",
    "\n",
    "print(\"Numero di esempi nel test di addestramento: \"+str(X_train_poly.shape[0]))\n",
    "print(\"Numero di features: \"+str(X_train_poly.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizziamo i dati\n",
    "**NOTA BENE** Per applicare la regolarizzazione è sempre necessario portare i dati sulla stessa scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_poly = ss.fit_transform(X_train_poly)\n",
    "X_test_poly = ss.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso il nostro set di addestramento contiene 354 e 105 features, abbastanza complesso !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riconoscere l'overfitting\n",
    "Evidenziare un problema di overfitting è molto semplice, un modello che ne soffre avrà memorizzato la struttura dei dati di addestramento, piuttosto che imparare da essi, quindi l'errore per le predizioni sul train set sarà molto basso, invece fallirà nel generalizzare, perciò l'errore nel test set sarà decisamente più alto.<br><br>\n",
    "Quindi per riconoscere l'overfitting è sufficente confrontare questi due valori, scriviamo una funzione che ci permette di farlo in modo da non dover scrivere più volte lo stesso codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_eval(model, X, Y):\n",
    "    \n",
    "    \"\"\"\n",
    "    model: il nostro modello predittivo già addestrato\n",
    "    X: una tupla contenente le prorietà del train set e test set (X_train, X_test)\n",
    "    Y: una tupla contenente target del train set e test set (Y_train, Y_test)\n",
    "    \"\"\"\n",
    "    \n",
    "    Y_pred_train = model.predict(X[0])\n",
    "    Y_pred_test = model.predict(X[1])\n",
    "    \n",
    "    mse_train = mean_squared_error(Y[0], Y_pred_train)\n",
    "    mse_test = mean_squared_error(Y[1], Y_pred_test)\n",
    "\n",
    "    r2_train = r2_score(Y[0], Y_pred_train)\n",
    "    r2_test = r2_score(Y[1], Y_pred_test)    \n",
    "    \n",
    "    print(\"Train set:  MSE=\"+str(mse_train)+\" R2=\"+str(r2_train))\n",
    "    print(\"Test set:  MSE=\"+str(mse_test)+\" R2=\"+str(r2_test))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressione lineare non regolarizzata\n",
    "Cominciamo eseguendo una regressione lineare (in realtà si tratta di una regressione polinomiale) senza applicare la regolarizzazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  MSE=4.116985074931637 R2=0.9514303225914078\n",
      "Test set:  MSE=29.550444547161653 R2=0.6451057885504312\n"
     ]
    }
   ],
   "source": [
    "ll = LinearRegression()\n",
    "ll.fit(X_train_poly, Y_train)\n",
    "\n",
    "overfit_eval(ll, (X_train_poly, X_test_poly),(Y_train, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello predice in maniera estremamente (o meglio dire eccessivamente) accurata i dati del train set, mentre è molto più scarso sul test set. Siamo di fronte ad un caso di overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regolarizzazione L2: Ridge Regression\n",
    "La ridge regression è un modello di regressione lineare che applica la **regolarizzazione L2**, la quale consiste nell'aggiungere una penalità per i pesi nella funzione di costo durante la fase di addestramento.<br>\n",
    "La penalità è data dalla somma dei quadrati dei pesi:\n",
    "$$\\lambda\\sum_{j=1}^{M}W_j^2$$<br>\n",
    "**Lambda** (conosciuto anche come **alpha**) è il **parametro di regolarizzazione** ed è un'altro iperparametro.\n",
    "Eseguiamo diverse Ridge regression per diversi valori di alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha=0.0001\n",
      "Train set:  MSE=4.09926340485998 R2=0.9516393920397678\n",
      "Test set:  MSE=28.91761846398874 R2=0.652705887879358\n",
      "Alpha=0.001\n",
      "Train set:  MSE=4.1135025099420846 R2=0.9514714077678218\n",
      "Test set:  MSE=28.420009267706448 R2=0.6586820627231176\n",
      "Alpha=0.01\n",
      "Train set:  MSE=4.208206127237709 R2=0.9503541522865029\n",
      "Test set:  MSE=26.813295018287196 R2=0.6779783405054157\n",
      "Alpha=0.1\n",
      "Train set:  MSE=4.747028830953758 R2=0.9439974508597073\n",
      "Test set:  MSE=23.63175511737725 R2=0.7161879211608522\n",
      "Alpha=1\n",
      "Train set:  MSE=5.875947305341798 R2=0.9306791596529952\n",
      "Test set:  MSE=17.634584627531503 R2=0.7882125937009091\n",
      "Alpha=10\n",
      "Train set:  MSE=8.812755521737856 R2=0.8960324885854233\n",
      "Test set:  MSE=17.15971577477419 R2=0.7939156621191287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1 ,1 ,10] #alpha corrispone a lambda\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha=\"+str(alpha))\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train_poly, Y_train)\n",
    "\n",
    "    overfit_eval(ridge, (X_train_poly, X_test_poly),(Y_train, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Ridge regression, applicando la regolarizzazione L2, ci permette di ridurre l'overfitting e portare l'R2 fino ad un valore di 0.791 per alpha uguale a 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regolarizzazione L1: Lasso\n",
    "Lasso è un modello di regressione lineare che applica la regolarizzazione L1, questa funziona in egual modo alla L2, con la differenza che il termine di regolarizza sarà dato dalla somma del valore assoluto dei pesi:\n",
    "$$\\lambda\\sum_{j=1}^{M}|W_j|$$<br>\n",
    "e viene sempre applicato alla funzione di costo durante la fase di addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha=0.0001\n",
      "Train set:  MSE=5.3911236526970985 R2=0.9363988132296843\n",
      "Test set:  MSE=29.701776720600666 R2=0.6432883230881479\n",
      "Alpha=0.001\n",
      "Train set:  MSE=5.407317548867133 R2=0.936207767525449\n",
      "Test set:  MSE=28.788018557306582 R2=0.6542623536919956\n",
      "Alpha=0.01\n",
      "Train set:  MSE=6.063858816900318 R2=0.9284622943178908\n",
      "Test set:  MSE=22.93324201265634 R2=0.7245769068863115\n",
      "Alpha=0.1\n",
      "Train set:  MSE=11.833211121207535 R2=0.8603989967405071\n",
      "Test set:  MSE=19.29615234281638 R2=0.7682575380960781\n",
      "Alpha=1\n",
      "Train set:  MSE=21.590985067091978 R2=0.7452827346818105\n",
      "Test set:  MSE=27.25804314512913 R2=0.6726370152499754\n",
      "Alpha=10\n",
      "Train set:  MSE=84.76451346994796 R2=0.0\n",
      "Test set:  MSE=83.76673764512785 R2=-0.0060197319476869016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.490e+02, tolerance: 3.001e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.866e+02, tolerance: 3.001e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.049e+02, tolerance: 3.001e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1 ,1 ,10] #alpha corrisponde a lambda\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"Alpha=\"+str(alpha))\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train_poly, Y_train)\n",
    "\n",
    "    overfit_eval(lasso, (X_train_poly, X_test_poly),(Y_train, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso ci permette di ottenere un modello ancora migliore, con un R2 di 0.803 per Lambda uguale a 0.1.<br>\n",
    "Da notare che per valori di lambda più grandi il modello peggiora, questo perché l'effetto della regolarizzazione sarà molto pesante e buona parte dei pesi saranno portati a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 ed L1 insieme: ElasticNet\n",
    "ElasticNet è un modello di regressione lineare che implementa entrambe le tecniche di regolarizzazone L2 ed L1.<br>\n",
    "Tramite il parametro <span style=\"font-family: Monaco\">l1_ration</span> possiamo controllare l'effetto delle due regolarizzazione\n",
    " * **<span style=\"font-family: Monaco\">l1_ration>0.5</span>** l'effetto della regolarizzazione L1 sarà più intenso rispetto alla L2.\n",
    " * **<span style=\"font-family: Monaco\">l1_ration<0.5</span>** l'effetto della regolarizzazione L2 sarà più intenso rispetto alla L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda is: 0.0001\n",
      "Train set:  MSE=5.391059281137911 R2=0.9363995726460551\n",
      "Test set:  MSE=29.46601758288404 R2=0.6461197374561598\n",
      "Lambda is: 0.001\n",
      "Train set:  MSE=5.463124643400418 R2=0.9355493894819877\n",
      "Test set:  MSE=26.23899793865832 R2=0.68487551962864\n",
      "Lambda is: 0.01\n",
      "Train set:  MSE=6.669947875220285 R2=0.9213120254906552\n",
      "Test set:  MSE=15.784424726986302 R2=0.8104325991533371\n",
      "Lambda is: 0.1\n",
      "Train set:  MSE=12.092531251957972 R2=0.8573396960952864\n",
      "Test set:  MSE=20.123693597792244 R2=0.7583189532244384\n",
      "Lambda is: 1\n",
      "Train set:  MSE=21.178857007859765 R2=0.7501447700119411\n",
      "Test set:  MSE=27.923580301576493 R2=0.6646440632674491\n",
      "Lambda is: 10\n",
      "Train set:  MSE=70.28359861834348 R2=0.1708369960353573\n",
      "Test set:  MSE=69.68198552608109 R2=0.16313498207951238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.665e+02, tolerance: 3.001e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.014e+03, tolerance: 3.001e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\python39\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.930e+02, tolerance: 3.001e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "alphas = [0.0001, 0.001, 0.01, 0.1 ,1 ,10]\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(\"Lambda is: \"+str(alpha))\n",
    "    elastic = ElasticNet(alpha=alpha, l1_ratio=0.5)\n",
    "    elastic.fit(X_train_poly, Y_train)\n",
    "    overfit_eval(elastic, (X_train_poly, X_test_poly),(Y_train, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizzando ElasticNet, e quindi entrambe le regolarizzazioni, abbiamo ottenuto un modello ancora migliore, con un R2 di 0.81 sul test set e 0.92 sul train set.<br>\n",
    "Abbiamo il nostro vincitore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Che differenza c'è tra la regolarizzazione L2 ed L1 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La differenza principale tra le due tecniche di regolarizzazione viste è la seguente:\n",
    "* La regolarizzazione L2 riduce la magnitudine dei pesi a valori più bassi.\n",
    "* La regolarizzazione L1 elimina le feature più deboli portando il loro peso a 0.\n",
    "Nella pratica la L2 porta quasi sempre a migliori risultati, ma utilizzarle entrambe con ElasticNet è anche un ottima soluzione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
