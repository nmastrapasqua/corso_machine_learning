{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross-Validation\n",
    "La k-fold cross-validation è un metodo di validazione del modello che non influisce sulla dimensione del train set.<br>\n",
    "In questo notebook creeremo un modello di classificazione per l'iris dataset e utilizzeremo una 10-folds cross-validation per la validazione.\n",
    "<br><br>\n",
    "Importiamo le librerie necessarie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carichiamo l'Iris Dataset in un Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\", \n",
    "                   names=[\"sepal length\",\"sepal width\",\"petal length\",\"petal width\",\"class\"])\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E creiamo gli array numpy per addestramento e test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop(\"class\",axis=1).values\n",
    "Y = iris[\"class\"].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per eseguire una cross-validation con scikit-learn abbiamo 2 opzioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-folds Cross Validation method\n",
    "Utilizziamo la classe KFold di sklearn per creare 10 folds e addestrare un modello per ognuna di esse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Accuracy=1.00\n",
      "Fold 1: Accuracy=1.00\n",
      "Fold 2: Accuracy=1.00\n",
      "Fold 3: Accuracy=0.91\n",
      "Fold 4: Accuracy=1.00\n",
      "Fold 5: Accuracy=1.00\n",
      "Fold 6: Accuracy=0.80\n",
      "Fold 7: Accuracy=1.00\n",
      "Fold 8: Accuracy=1.00\n",
      "Fold 9: Accuracy=0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "scores = []\n",
    "              \n",
    "for k, (train, test) in enumerate(kfold.split(X_train)):\n",
    "    lr.fit(X_train[train], Y_train[train])\n",
    "    score = lr.score(X_train[test],Y_train[test])\n",
    "    scores.append(score)\n",
    "    print(\"Fold %d: Accuracy=%.2f\" %(k, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo calcolare l'accuracy come la media dei punteggi sui 10 modelli ottenuti tramite la cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy = 0.96\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.array(scores).mean()\n",
    "print(\"\\nValidation Accuracy = %.2f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un problema di questo approccio è che le classi nelle folds potrebbero essere sbilanciare<br>\n",
    "(ES. su 100 esempi appartenenti ad una fold, 77 esempi appartengono alla classe positiva e 23 alla classe negativa).\n",
    "<br><br>\n",
    "Per risolvere questo problema possiamo utilizzare la classe <span style=\"font-family: Monaco\">StratifiedKFold</span> che crea folds bilanciando le classi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Accuracy=1.00\n",
      "Fold 1: Accuracy=1.00\n",
      "Fold 2: Accuracy=1.00\n",
      "Fold 3: Accuracy=0.91\n",
      "Fold 4: Accuracy=1.00\n",
      "Fold 5: Accuracy=0.90\n",
      "Fold 6: Accuracy=1.00\n",
      "Fold 7: Accuracy=0.90\n",
      "Fold 8: Accuracy=1.00\n",
      "Fold 9: Accuracy=1.00\n",
      "\n",
      "Validation Accuracy = 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "scores = []\n",
    "              \n",
    "for k, (train, test) in enumerate(kfold.split(X_train,Y_train)):\n",
    "    lr.fit(X_train[train], Y_train[train])\n",
    "    score = lr.score(X_train[test],Y_train[test])\n",
    "    scores.append(score)\n",
    "    print(\"Fold %d: Accuracy=%.2f\" %(k, score))\n",
    "    \n",
    "print(\"\\nValidation Accuracy = %.2f\" % (np.array(scores).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation scorer\n",
    "La seconda opzione che scikit-learn offre è più semplice e più efficace.<br>\n",
    "E' possibile utilizzare la cross_validation come funzione di scoring passandogli il modello, questa funzione utilizza internamente la <span style=\"font-family: Monaco\">StratifiedKFold</span> quindi le classi saranno bilanciate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 score=1.0000\n",
      "Fold 2 score=1.0000\n",
      "Fold 3 score=1.0000\n",
      "Fold 4 score=0.9091\n",
      "Fold 5 score=1.0000\n",
      "Fold 6 score=0.9000\n",
      "Fold 7 score=1.0000\n",
      "Fold 8 score=0.9000\n",
      "Fold 9 score=1.0000\n",
      "Fold 10 score=1.0000\n",
      "\n",
      "Validation Accuracy = 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "scores = cross_val_score(lr, X_train, Y_train, cv=10)\n",
    "\n",
    "for fold,score in enumerate(scores):\n",
    "    print(\"Fold %d score=%.4f\" % (fold+1,score))\n",
    "    \n",
    "print(\"\\nValidation Accuracy = %.2f\" % scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un vantaggio di questa funzione è che, considerando che la creazione del modello per ogni fold avviene in maniera indipendente, è possibile parallelizzare il lavoro distribuendolo su più CPU.<br>\n",
    "Per farlo è sufficente specificare all'interno del parametro n_jobs il numero di CPU da utilizzare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   8 out of  10 | elapsed:    4.5s remaining:    1.1s\n",
      "[Parallel(n_jobs=7)]: Done  10 out of  10 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.90909091, 1.        ,\n",
       "       0.9       , 1.        , 0.9       , 1.        , 1.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "cross_val_score(lr, X_train, Y_train, cv=10, n_jobs=7, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA BENE**<br>Una volta validato il modello, utilizzando una di queste due opzioni (la seconda è più consigliata) questo va **sempre** riaddestrato sull'intero train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
